{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pancreatic Cancer Detection Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing \n",
    "\n",
    "Ideas we should probably do for both datasets:\n",
    "    - load data. remove any Null/NaN data, see if there are negative values and remove those if applicable.\n",
    "    - if blank data cells, impute the data. scale the appropriate data columns\n",
    "\n",
    "\n",
    "    - split the dataset into X and y subsets for passing into models\n",
    "        - which really means also split into 80/20; 80% training(validation included) and 20% test\n",
    "\n",
    "    - Note: we should do some data visualizations --> heatmaps? histograms of label distributions for proof\n",
    "        - of good splits. mutual information??? (need to better understand if its useful)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        LYVE1         TFF1       REG1B  Creatinine  Diagnosis\n",
      "0    0.893219   654.282174   52.948840     1.83222          1\n",
      "1    2.037585   209.488250   94.467030     0.97266          1\n",
      "2    0.145589   461.141000  102.366000     0.78039          1\n",
      "3    0.002805   142.950000   60.579000     0.70122          1\n",
      "4    0.000860    41.088000   65.540000     0.21489          1\n",
      "..        ...          ...         ...         ...        ...\n",
      "585  7.058209   525.178000  156.241000     0.52026          3\n",
      "586  8.341207   245.947000   16.915000     0.85956          3\n",
      "587  7.674707   537.286000  289.701000     1.36851          3\n",
      "588  8.206777   722.523000  205.930000     1.33458          3\n",
      "589  8.200958  2021.321078  411.938275     1.50423          3\n",
      "\n",
      "[590 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Loading urinary biomarker dataset\n",
    "urinary_df = pd.read_csv('urinaryBiomarkerData.csv')\n",
    "urinary_df = urinary_df.drop(columns=['sample_id','patient_cohort','sample_origin','age','sex','stage','benign_sample_diagnosis','plasma_CA19_9','REG1A'])\n",
    "columnOrder = [\"LYVE1\", \"TFF1\", \"REG1B\", \"creatinine\", \"diagnosis\"]\n",
    "# Reorder the columns in the DataFrame\n",
    "urinary_df = urinary_df[columnOrder]\n",
    "urinary_df.rename(columns={'diagnosis': 'Diagnosis', \"creatinine\": \"Creatinine\"}, inplace=True)\n",
    "\n",
    "print(urinary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "0   -0.631661  0.055876 -0.299975    1.529927          0\n",
      "1   -0.298597 -0.384680 -0.088256    0.183680          0\n",
      "2   -0.849256 -0.135425 -0.047976   -0.117454          0\n",
      "3   -0.890812 -0.450584 -0.261065   -0.241451          0\n",
      "4   -0.891378 -0.551475 -0.235767   -1.003143          0\n",
      "..        ...       ...       ...         ...        ...\n",
      "585  1.162636 -0.071998  0.226755   -0.524871          1\n",
      "586  1.536048 -0.348568 -0.483726    0.006542          1\n",
      "587  1.342066 -0.060005  0.907324    0.803662          1\n",
      "588  1.496923  0.123466  0.480141    0.750521          1\n",
      "589  1.495229  1.409888  1.530663    1.016227          1\n",
      "\n",
      "[590 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing urinary biomarker dataset\n",
    "# NOTE: There are no negative or Null/NaN values in the dataset\n",
    "    # So, no need to remove samples or impute the data\n",
    "    # Only need to scale the appropriate data columns\n",
    "\n",
    "# Relabel non-cancer to be 0, cancer to be 1\n",
    "urinary_df['Diagnosis'] = urinary_df['Diagnosis'].replace(2, 0)\n",
    "urinary_df['Diagnosis'] = urinary_df['Diagnosis'].replace(1, 0)\n",
    "urinary_df['Diagnosis'] = urinary_df['Diagnosis'].replace(3, 1)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "val_cols = urinary_df.loc[:, ~urinary_df.columns.isin(['Diagnosis'])]\n",
    "urinary_df[val_cols.columns] = scaler.fit_transform(val_cols)\n",
    "print(urinary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length is 472... test length is 118\n",
      "train_urinary_data: \n",
      "         LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "569  1.729341  2.236736  0.169357    2.451043          1\n",
      "467  0.896179  0.074365 -0.180192   -0.046599          1\n",
      "63  -0.886494 -0.574698 -0.503176   -1.144853          0\n",
      "507  0.791824  0.162043 -0.385763    1.405930          1\n",
      "212  0.023265 -0.478069 -0.346764   -0.353048          0\n",
      "..        ...       ...       ...         ...        ...\n",
      "456  0.744419  0.296983  1.504107   -0.985429          1\n",
      "360  0.280443 -0.286411 -0.396328   -0.613440          0\n",
      "439  1.707320  2.481479  1.339816   -0.294592          1\n",
      "174 -0.891536 -0.568532 -0.396628   -1.215708          0\n",
      "122 -0.889930 -0.479479 -0.425504    0.945372          0\n",
      "\n",
      "[472 rows x 5 columns]\n",
      "test_urinary_data: \n",
      "         LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "424 -0.365876  0.137482  0.403048    0.219107          1\n",
      "583  0.786063  1.334465  4.274874   -0.294592          1\n",
      "210  0.522988  2.660132  3.021212    0.431673          0\n",
      "537  1.037334  0.000741  0.675174   -0.294592          1\n",
      "53  -0.889183 -0.583847 -0.528004    0.041970          0\n",
      "..        ...       ...       ...         ...        ...\n",
      "265  0.400738 -0.164869 -0.418843   -1.056284          0\n",
      "112 -0.083461 -0.347726 -0.532874    1.653923          0\n",
      "324 -0.891563 -0.393914 -0.543915   -1.251136          0\n",
      "18  -0.226486 -0.324938 -0.225935    0.679666          0\n",
      "6   -0.840876 -0.475776  0.206541   -0.365447          0\n",
      "\n",
      "[118 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split data into training/validation and test (80/20)\n",
    "\n",
    "train_urinary_data, test_urinary_data = train_test_split(urinary_df, test_size=0.2, random_state=4, shuffle=True)\n",
    "\n",
    "print(\"train length is \" + str(len(train_urinary_data)) + \"... test length is \" + str(len(test_urinary_data)))\n",
    "print(\"train_urinary_data: \\n\", train_urinary_data)\n",
    "print(\"test_urinary_data: \\n\", test_urinary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation\n",
    "5 classifiers: Random Forest Classifier. XGBoost, Support Vector Machine, Gaussian Naive Bayes, and K Neighbors Classifier\n",
    "- we want to initialize all 5 models, probably default hyperparameters for most values.\n",
    "    - it's 5 models per dataset, so we'll have 10 in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: add/remove/adjust hyperparameters as you see fit\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42, learning_rate=0.01)\n",
    "svm = SVC(C=1, kernel=\"rbf\", random_state=42)\n",
    "gnb = GaussianNB()\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation\n",
    "\n",
    "- Train the models using 10-fold cross validation \n",
    "    - we can probably do this in 2 separate cross-validation loops. \n",
    "        - first one is for urinary dataset and we train/validate all 5 models (get their scores and loss? too)\n",
    "        - repeat for second dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF training accuracies:  [0.7916666666666666, 0.9166666666666666, 0.8297872340425532, 0.7021276595744681, 0.7872340425531915, 0.7659574468085106, 0.8085106382978723, 0.8085106382978723, 0.851063829787234, 0.7872340425531915]\n",
      "RF mean:  0.8048758865248228\n",
      "RF standard dev:  0.05305308530300568 \n",
      "\n",
      "XGB training accuracies:  [0.7708333333333334, 0.8541666666666666, 0.7659574468085106, 0.6808510638297872, 0.8085106382978723, 0.7659574468085106, 0.8723404255319149, 0.8297872340425532, 0.8297872340425532, 0.7659574468085106]\n",
      "XGB mean:  0.7944148936170212\n",
      "XGB standard dev:  0.053128212954321484 \n",
      "\n",
      "SVM training accuracies:  [0.7708333333333334, 0.8958333333333334, 0.9148936170212766, 0.6382978723404256, 0.8085106382978723, 0.8085106382978723, 0.7872340425531915, 0.8085106382978723, 0.8297872340425532, 0.851063829787234]\n",
      "SVM mean:  0.8113475177304965\n",
      "SVM standard dev:  0.07209038669915623 \n",
      "\n",
      "GNB training accuracies:  [0.7708333333333334, 0.875, 0.8297872340425532, 0.6170212765957447, 0.6808510638297872, 0.7446808510638298, 0.7659574468085106, 0.7659574468085106, 0.8085106382978723, 0.7446808510638298]\n",
      "GNB mean:  0.7603280141843972\n",
      "GNB standard dev:  0.0691466771998721 \n",
      "\n",
      "KNN training accuracies:  [0.7916666666666666, 0.8333333333333334, 0.8936170212765957, 0.6382978723404256, 0.8297872340425532, 0.8297872340425532, 0.8085106382978723, 0.7659574468085106, 0.7659574468085106, 0.8085106382978723]\n",
      "KNN mean:  0.7965425531914894\n",
      "KNN standard dev:  0.06341131787104846 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf_scores = []\n",
    "xgb_scores = []\n",
    "svm_scores = []\n",
    "gnb_scores = []\n",
    "knn_scores = []\n",
    "\n",
    "X = train_urinary_data\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, val_index in kf.split(X): #10 folds\n",
    "    # set up training data\n",
    "    train_chunk = X.iloc[train_index]\n",
    "    y_train = train_chunk['Diagnosis']\n",
    "    X_train = train_chunk.drop(columns=['Diagnosis'])\n",
    "\n",
    "    # set up validation data\n",
    "    val_chunk = X.iloc[val_index]\n",
    "    y_val = val_chunk['Diagnosis']\n",
    "    X_val = val_chunk.drop(columns=['Diagnosis'])\n",
    "\n",
    "    # Random Forest\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred = rf.predict(X_val)\n",
    "    rf_score = accuracy_score(y_val, rf_pred)\n",
    "    rf_scores.append(rf_score)\n",
    "\n",
    "    # XGBoost\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_pred = xgb.predict(X_val)\n",
    "    xgb_score = accuracy_score(y_val, xgb_pred)\n",
    "    xgb_scores.append(xgb_score)\n",
    "\n",
    "    # SVM\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm_pred = svm.predict(X_val)\n",
    "    svm_score = accuracy_score(y_val, svm_pred)\n",
    "    svm_scores.append(svm_score)\n",
    "\n",
    "    # Gaussian Naive Bayes\n",
    "    gnb.fit(X_train, y_train)\n",
    "    gnb_pred = gnb.predict(X_val)\n",
    "    gnb_score = accuracy_score(y_val, gnb_pred)\n",
    "    gnb_scores.append(gnb_score)\n",
    "\n",
    "    # KNearestNeighbors\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_pred = knn.predict(X_val)\n",
    "    knn_score = accuracy_score(y_val, knn_pred)\n",
    "    knn_scores.append(knn_score)\n",
    "\n",
    "print(\"RF training accuracies: \", rf_scores)\n",
    "print(\"RF mean: \", np.mean(rf_scores))\n",
    "print(\"RF standard dev: \", np.std(rf_scores), \"\\n\")\n",
    "\n",
    "print(\"XGB training accuracies: \", xgb_scores)\n",
    "print(\"XGB mean: \", np.mean(xgb_scores))\n",
    "print(\"XGB standard dev: \", np.std(xgb_scores), \"\\n\")\n",
    "\n",
    "print(\"SVM training accuracies: \", svm_scores)\n",
    "print(\"SVM mean: \", np.mean(svm_scores))\n",
    "print(\"SVM standard dev: \", np.std(svm_scores), \"\\n\")\n",
    "\n",
    "print(\"GNB training accuracies: \", gnb_scores)\n",
    "print(\"GNB mean: \", np.mean(gnb_scores))\n",
    "print(\"GNB standard dev: \", np.std(gnb_scores), \"\\n\")\n",
    "\n",
    "print(\"KNN training accuracies: \", knn_scores)\n",
    "print(\"KNN mean: \", np.mean(knn_scores))\n",
    "print(\"KNN standard dev: \", np.std(knn_scores), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Models\n",
    "\n",
    "- Test each of the models on the appropriate dataset and store values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF test accuracy:  0.7796610169491526\n",
      "XGB test accuracy:  0.7711864406779662\n",
      "SVM test accuracy:  0.7966101694915254\n",
      "GNB test accuracy:  0.7711864406779662\n",
      "KNN test accuracy:  0.8050847457627118\n"
     ]
    }
   ],
   "source": [
    "# set up test data\n",
    "X_test = test_urinary_data.drop(columns=['Diagnosis'])\n",
    "y_test = test_urinary_data['Diagnosis']\n",
    "\n",
    "# Random Forest\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "print(\"RF test accuracy: \", rf_acc)\n",
    "\n",
    "# XGBoost\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "xgb_acc = accuracy_score(y_test, xgb_pred)\n",
    "print(\"XGB test accuracy: \", xgb_acc)\n",
    "\n",
    "# SVM\n",
    "svm_pred = svm.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, svm_pred)\n",
    "print(\"SVM test accuracy: \", svm_acc)\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb_pred = gnb.predict(X_test)\n",
    "gnb_acc = accuracy_score(y_test, gnb_pred)\n",
    "print(\"GNB test accuracy: \", gnb_acc)\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_pred = knn.predict(X_test)\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "print(\"KNN test accuracy: \", knn_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------- NON URINARY DATA WORK --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal pancreas RNA-seq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "0   0.603023 -1.177057 -0.312348    0.761342          0\n",
      "1  -0.527645 -1.177057 -0.312348    1.162652          0\n",
      "2  -0.527645  2.075338 -0.312348    0.069336          0\n",
      "3  -0.527645  0.449140  2.030259    0.732340          0\n",
      "4  -0.527645 -0.247802 -0.312348   -0.348836          0\n",
      "5  -0.527645  1.610710 -0.312348   -0.999700          0\n",
      "6  -0.527645 -0.944743 -0.312348   -0.092537          0\n",
      "7  -0.527645 -1.177057 -0.312348   -0.287459          0\n",
      "8  -0.527645  1.378396 -0.312348   -0.514756          0\n",
      "9  -0.527645 -0.015488 -0.312348   -1.301863          0\n",
      "10  0.603023 -1.177057 -0.312348    1.524843          0\n",
      "11  0.603023 -1.177057 -0.312348    0.634542          0\n",
      "12 -0.527645  0.216826 -0.312348    0.202206          0\n",
      "13 -0.527645  0.681454  4.372865   -0.212593          0\n",
      "14  1.733690 -0.247802 -0.312348   -0.626718          0\n",
      "15 -0.527645  1.378396 -0.312348   -0.043975          0\n",
      "16 -0.527645 -0.247802 -0.312348   -0.173474          0\n",
      "17 -0.527645 -0.712429 -0.312348   -0.389979          0\n",
      "18  0.603023  0.216826 -0.312348   -0.670558          0\n",
      "19 -0.527645  1.146082 -0.312348   -0.816244          0\n",
      "20  2.864358 -1.177057 -0.312348    2.521036          0\n",
      "21 -0.527645 -1.177057 -0.312348    1.697507          0\n",
      "22 -0.527645  1.610710 -0.312348    2.156822          0\n",
      "23 -0.527645  0.681454  2.030259    0.353962          0\n",
      "24 -0.527645 -0.480116 -0.312348   -0.165380          0\n",
      "25  2.864358 -0.015488 -0.312348   -0.550503          0\n",
      "26 -0.527645 -1.177057 -0.312348   -0.866155          0\n",
      "27 -0.527645 -0.480116 -0.312348   -1.079288          0\n",
      "28 -0.527645  0.449140 -0.312348   -1.279605          0\n",
      "29  1.733690  0.913768 -0.312348   -1.396963          0\n"
     ]
    }
   ],
   "source": [
    "# Normal pancreas dataset 1\n",
    "markers = ['LYVE1','TFF1','REG1B','GPX1']\n",
    "\n",
    "rawPancNormData1 = pd.read_csv(\"pancreaticNormalSeqData/GSE205163_znf808_ko_raw_counts_S0-S4.tsv\",  sep='\\t')\n",
    "filtRawPancNormData1 = rawPancNormData1[rawPancNormData1['Gene'].str.endswith(('LYVE1','REG1B','TFF1','GPX1'))]\n",
    "filtRawPancNormData1 = filtRawPancNormData1.set_index('Gene')\n",
    "filtRawPancNormData1 = filtRawPancNormData1.transpose()\n",
    "filtRawPancNormData1 = filtRawPancNormData1.reset_index(drop=True)\n",
    "filtRawPancNormData1.columns = markers\n",
    "filtRawPancNormData1.rename(columns={\"GPX1\": \"Creatinine\"}, inplace=True)\n",
    "#print(filtRawPancNormData1)\n",
    "\n",
    "filtRawPancNormData1Scaler = StandardScaler()\n",
    "scaledRawPancNormData1 = filtRawPancNormData1Scaler.fit_transform(filtRawPancNormData1)\n",
    "scaledRawPancNormData1 = pd.DataFrame(scaledRawPancNormData1, columns=filtRawPancNormData1.columns)\n",
    "scaledRawPancNormData1[\"Diagnosis\"] = 0\n",
    "\n",
    "print(scaledRawPancNormData1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene     LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "0     1.212172 -0.414569 -0.222204   -0.728370          0\n",
      "1    -0.601634  2.289087 -0.222204   -0.762900          0\n",
      "2    -0.601634  1.401099 -0.222204   -0.905547          0\n",
      "3     1.992331  1.282733 -0.222204   -1.322138          0\n",
      "4    -0.601634  2.063121 -0.222204   -1.445888          0\n",
      "5     0.924537  4.151805 -0.222204   -1.653851          0\n",
      "6     2.169985  0.836218 -0.222204   -1.450046          0\n",
      "7    -0.601634  1.137392 -0.222204   -1.582078          0\n",
      "8     0.805753 -0.310619 -0.222204   -1.670140          0\n",
      "9    -0.601634 -0.602931 -0.222204   -0.294469          0\n",
      "10   -0.601634 -0.391989 -0.222204   -0.241374          0\n",
      "11   -0.601634 -0.350597 -0.222204   -0.183727          0\n",
      "12   -0.601634 -0.602931 -0.222204    0.497534          0\n",
      "13   -0.601634 -0.602931 -0.222204    0.060106          0\n",
      "14   -0.601634 -0.602931 -0.222204    0.028425          0\n",
      "15    2.292054 -0.001918  3.931583    2.360045          0\n",
      "16   -0.601634 -0.602931 -0.222204    1.325185          0\n",
      "17   -0.601634 -0.385824 -0.222204    1.636096          0\n",
      "18   -0.601634 -0.108451 -0.222204   -1.355897          0\n",
      "19   -0.601634  0.184012 -0.222204   -1.224700          0\n",
      "20   -0.601634 -0.167431 -0.222204   -1.360988          0\n",
      "21    0.694340 -0.602931 -0.222204    0.514384          0\n",
      "22    0.599920 -0.353370 -0.222204   -0.132897          0\n",
      "23   -0.601634 -0.311554 -0.222204    0.149604          0\n",
      "24   -0.601634 -0.602931 -0.222204    1.071371          0\n",
      "25    0.854264 -0.602931 -0.222204    1.524868          0\n",
      "26   -0.601634  1.153943 -0.222204    1.122840          0\n",
      "27   -0.601634  0.457220 -0.222204    0.697802          0\n",
      "28    2.949525 -0.602931 -0.222204    0.696007          0\n",
      "29    0.343139 -0.602931 -0.222204    0.096359          0\n",
      "30   -0.601634 -0.320462 -0.222204   -0.442754          0\n",
      "31   -0.601634 -0.352144 -0.222204    1.531455          0\n",
      "32   -0.601634 -0.602931 -0.222204    0.163715          0\n",
      "33   -0.601634 -0.032020 -0.222204    0.589219          0\n",
      "34   -0.601634 -0.602931 -0.222204    0.530845          0\n",
      "35   -0.601634 -0.602931 -0.222204    0.954884          0\n",
      "36   -0.601634 -0.602931  4.956578    0.189093          0\n",
      "37   -0.601634 -0.602931 -0.222204    0.025655          0\n",
      "38    1.938846 -0.602931 -0.222204    0.197995          0\n",
      "39    0.670524 -0.602931 -0.222204    0.384630          0\n",
      "40   -0.601634 -0.602931 -0.222204    0.344501          0\n",
      "41   -0.601634 -0.602931 -0.222204    0.065146          0\n"
     ]
    }
   ],
   "source": [
    "# Normal pancreas dataset 2\n",
    "rawPancNormData2 = pd.read_csv(\"pancreaticNormalSeqData/GSE216854_normalized_counts.txt\", sep='\\t')\n",
    "filtRawPancNormData2 = rawPancNormData2[rawPancNormData2['gene'].isin(markers)]\n",
    "filtRawPancNormData2 = filtRawPancNormData2.set_index('gene')\n",
    "filtRawPancNormData2 = filtRawPancNormData2.transpose()\n",
    "filtRawPancNormData2 = filtRawPancNormData2.reset_index(drop=True)\n",
    "filtRawPancNormData2.rename(columns={\"GPX1\": \"Creatinine\"}, inplace=True)\n",
    "\n",
    "columnOrder = [\"LYVE1\", \"TFF1\", \"REG1B\", \"Creatinine\"]\n",
    "# Reorder the columns in the DataFrame\n",
    "filtRawPancNormData2 = filtRawPancNormData2[columnOrder]\n",
    "#print(filtRawPancNormData2)\n",
    "\n",
    "filtRawPancNormData1Scaler2 = StandardScaler()\n",
    "scaledRawPancNormData2 = filtRawPancNormData1Scaler2.fit_transform(filtRawPancNormData2)\n",
    "scaledRawPancNormData2 = pd.DataFrame(scaledRawPancNormData2, columns=filtRawPancNormData2.columns)\n",
    "scaledRawPancNormData2[\"Diagnosis\"] = 0\n",
    "print(scaledRawPancNormData2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symbol     LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "0      -0.577293  0.366796 -0.160845    1.125271          0\n",
      "1      -0.577293  1.197512 -0.160845    1.873122          0\n",
      "2      -0.032524  0.482173 -0.160845    0.631829          0\n",
      "3      -0.032524  0.020665 -0.160845    0.577313          0\n",
      "4      -0.577293  0.424485 -0.160845    0.578711          0\n",
      "..           ...       ...       ...         ...        ...\n",
      "62     -0.577293 -0.521608 -0.160845   -0.412366          0\n",
      "63      0.512246 -0.694674 -0.160845    0.041936          0\n",
      "64     -0.577293 -0.821589 -0.160845    0.219463          0\n",
      "65     -0.032524 -0.683136 -0.160845   -0.243226          0\n",
      "66     -0.577293 -0.729287 -0.160845    0.075484          0\n",
      "\n",
      "[67 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Normal pancreas dataset 3\n",
    "rawPancNormData3 = pd.read_csv(\"pancreaticNormalSeqData/GSE228662_RNA_raw_read_counts.tsv\", sep='\\t')\n",
    "filtRawPancNormData3 = rawPancNormData3[rawPancNormData3['symbol'].isin(markers)]\n",
    "filtRawPancNormData3 = filtRawPancNormData3.set_index('symbol')\n",
    "filtRawPancNormData3 = filtRawPancNormData3.drop(columns=['chrom','start','end','gene'])\n",
    "filtRawPancNormData3 = filtRawPancNormData3.transpose()\n",
    "filtRawPancNormData3 = filtRawPancNormData3.reset_index(drop=True)\n",
    "\n",
    "filtRawPancNormData3.rename(columns={\"GPX1\": \"Creatinine\"}, inplace=True)\n",
    "columnOrder = [\"LYVE1\", \"TFF1\", \"REG1B\", \"Creatinine\"]\n",
    "\n",
    "# Reorder the columns in the DataFrame\n",
    "filtRawPancNormData3 = filtRawPancNormData3[columnOrder]\n",
    "#print(filtRawPancNormData3)\n",
    "\n",
    "filtRawPancNormData1Scaler3 = StandardScaler()\n",
    "scaledRawPancNormData3 = filtRawPancNormData1Scaler3.fit_transform(filtRawPancNormData3)\n",
    "scaledRawPancNormData3 = pd.DataFrame(scaledRawPancNormData3, columns=filtRawPancNormData3.columns)\n",
    "scaledRawPancNormData3[\"Diagnosis\"] = 0\n",
    "print(scaledRawPancNormData3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "0   0.603023 -1.177057 -0.312348    0.761342          0\n",
      "1  -0.527645 -1.177057 -0.312348    1.162652          0\n",
      "2  -0.527645  2.075338 -0.312348    0.069336          0\n",
      "3  -0.527645  0.449140  2.030259    0.732340          0\n",
      "4  -0.527645 -0.247802 -0.312348   -0.348836          0\n",
      "..       ...       ...       ...         ...        ...\n",
      "62 -0.577293 -0.521608 -0.160845   -0.412366          0\n",
      "63  0.512246 -0.694674 -0.160845    0.041936          0\n",
      "64 -0.577293 -0.821589 -0.160845    0.219463          0\n",
      "65 -0.032524 -0.683136 -0.160845   -0.243226          0\n",
      "66 -0.577293 -0.729287 -0.160845    0.075484          0\n",
      "\n",
      "[139 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all 3 normal pancreas datasets\n",
    "#allPancNormData = pd.concat([filtRawPancNormData1, filtRawPancNormData2, filtRawPancNormData3], sort=False)\n",
    "#print(allPancNormData)\n",
    "\n",
    "allPancNormData = pd.concat([scaledRawPancNormData1, scaledRawPancNormData2, scaledRawPancNormData3], sort=False)\n",
    "print(allPancNormData)\n",
    "\n",
    "# NOTE: allPancNormData already has no zeros or NaN/Null, does not need imputing or more processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pancreatic cancer RNA-seq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "rawPancCancData1 = pd.read_csv(\"pancreaticCancerSeqData/GSE232860_allsamples.deseq.normalized.counts.csv\")\n",
    "rawPancCancData2 = pd.read_excel(\"pancreaticCancerSeqData/GSE245306_FKPM.xlsx\")\n",
    "\n",
    "rawPancCancData3 = pd.read_csv(\"pancreaticCancerSeqData/tumor.counts.sub.tsv\", sep='\\t')\n",
    "rawPancCancData3 = rawPancCancData3.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "0  -0.315544  2.008313 -0.543365   -0.046518          1\n",
      "1  -0.581683  2.415103 -0.534482   -0.740781          1\n",
      "2  -0.585285  2.299507 -0.489057    0.271683          1\n",
      "3  -0.750723  0.599046 -0.452496   -0.729316          1\n",
      "4   0.046597 -0.554481 -0.160474    1.918426          1\n",
      "5   0.371750  0.324675 -0.486279   -0.629386          1\n",
      "6   0.614754 -0.618860 -0.518384    0.311472          1\n",
      "7   3.955835 -0.684014  0.051366   -1.351388          1\n",
      "8   0.056674 -0.602712 -0.521555   -0.034005          1\n",
      "9   1.293589 -0.056772 -0.390424   -1.443193          1\n",
      "10  0.034731  0.592024 -0.530837    0.678888          1\n",
      "11 -0.164512  0.366374 -0.540116   -0.737920          1\n",
      "12 -1.064816 -0.754403  0.276978    0.695200          1\n",
      "13 -0.262819 -0.501485  0.182592   -0.799021          1\n",
      "14 -0.160552  0.059531  0.173587    0.652034          1\n",
      "15 -0.479314 -0.754403 -0.502960    0.270555          1\n",
      "16 -0.292546 -0.754403  4.248813   -0.811870          1\n",
      "17 -0.481052 -0.754403 -0.543953    0.907967          1\n",
      "18  0.266584 -0.365430  0.443695   -1.022374          1\n",
      "19 -0.415810 -0.754403 -0.142142    0.908884          1\n",
      "20 -0.838928 -0.754403  0.437871    2.490400          1\n",
      "21 -0.246932 -0.754403  0.541621   -0.759741          1\n"
     ]
    }
   ],
   "source": [
    "#Only has Reg1\n",
    "rowsToKeep = [\"Gpx1\", \"Lyve1\", \"Reg1\", \"Tff1\"]\n",
    "rawPancCancData1.rename(columns={'Unnamed: 0': 'GeneNames'}, inplace=True)\n",
    "#print(rawPancCancData1.shape)\n",
    "\n",
    "filtRawPancCancData1 = rawPancCancData1[rawPancCancData1['GeneNames'].isin(rowsToKeep)]\n",
    "filtRawPancCancData1 = filtRawPancCancData1.transpose()\n",
    "filtRawPancCancData1.reset_index(inplace=True, drop=True)\n",
    "filtRawPancCancData1.columns = filtRawPancCancData1.iloc[0]\n",
    "filtRawPancCancData1 = filtRawPancCancData1[1:]\n",
    "\n",
    "filtRawPancCancData1.rename(columns={'Reg1': 'REG1B', \"Gpx1\": \"Creatinine\", \"Tff1\": \"TFF1\", \"Lyve1\": \"LYVE1\"}, inplace=True)\n",
    "columnOrder = [\"LYVE1\", \"TFF1\", \"REG1B\", \"Creatinine\"]\n",
    "\n",
    "# Reorder the columns in the DataFrame\n",
    "filtRawPancCancData1 = filtRawPancCancData1[columnOrder]\n",
    "\n",
    "# Impute missing values in each column if needed\n",
    "filtRawPancCancData1 = filtRawPancCancData1.fillna(filtRawPancCancData1.median())\n",
    "#print(filtRawPancCancData1)\n",
    "\n",
    "filtRawPancCancData1Scaler = StandardScaler()\n",
    "scaledRawPancCancData1 = filtRawPancCancData1Scaler.fit_transform(filtRawPancCancData1)\n",
    "scaledRawPancCancData1 = pd.DataFrame(scaledRawPancCancData1, columns=filtRawPancCancData1.columns)\n",
    "scaledRawPancCancData1[\"Diagnosis\"] = 1\n",
    "print(scaledRawPancCancData1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "0  0.032969  1.550013  2.945148    1.319633          1\n",
      "1  2.855572 -0.558612 -0.428273    2.151116          1\n",
      "2 -0.611502 -0.558612 -0.440346   -0.747143          1\n",
      "3 -0.611502 -0.558612 -0.440346   -1.003820          1\n",
      "4 -0.611502 -0.558612 -0.440346   -0.983581          1\n",
      "5 -0.608904 -0.558612 -0.440346   -0.753642          1\n",
      "6  0.149489 -0.363988 -0.017810    0.207282          1\n",
      "7  0.177499 -0.389758 -0.430109    0.413563          1\n",
      "8 -0.393700 -0.372597 -0.413068   -0.560482          1\n",
      "9 -0.378419  2.369388  0.105496   -0.042926          1\n"
     ]
    }
   ],
   "source": [
    "rowsToKeep = [\"Gpx1\", \"Lyve1\", \"Reg1\", \"Tff1\"]\n",
    "\n",
    "filtRawPancCancData2 = rawPancCancData2[rawPancCancData2['Gene'].isin(rowsToKeep)]\n",
    "#print(filtRawPancCancData2.shape)\n",
    "#print(filtRawPancCancData2)\n",
    "\n",
    "filtRawPancCancData2 = filtRawPancCancData2.transpose()\n",
    "#print(filtRawPancCancData2)\n",
    "filtRawPancCancData2.reset_index(inplace=True, drop=True)\n",
    "#print(filtRawPancCancData2)\n",
    "#print(filtRawPancCancData2.shape)\n",
    "\n",
    "filtRawPancCancData2.columns = filtRawPancCancData2.iloc[0]\n",
    "filtRawPancCancData2 = filtRawPancCancData2[1:]\n",
    "filtRawPancCancData2 = filtRawPancCancData2.drop([1, 2])  # Remove the second and third rows\n",
    "\n",
    "filtRawPancCancData2.rename(columns={'Reg1': 'REG1B', \"Gpx1\": \"Creatinine\", \"Tff1\": \"TFF1\", \"Lyve1\": \"LYVE1\"}, inplace=True)\n",
    "columnOrder = [\"LYVE1\", \"TFF1\", \"REG1B\", \"Creatinine\"]\n",
    "\n",
    "# Reorder the columns in the DataFrame\n",
    "filtRawPancCancData2 = filtRawPancCancData2[columnOrder]\n",
    "#print(filtRawPancCancData2)\n",
    "#print(filtRawPancCancData2.shape)\n",
    "\n",
    "# Impute missing values in each column if needed\n",
    "filtRawPancCancData2 = filtRawPancCancData2.fillna(filtRawPancCancData2.median())\n",
    "#print(filtRawPancCancData2)\n",
    "\n",
    "filtRawPancCancData1Scaler2 = StandardScaler()\n",
    "scaledRawPancCancData2 = filtRawPancCancData1Scaler2.fit_transform(filtRawPancCancData2)\n",
    "scaledRawPancCancData2 = pd.DataFrame(scaledRawPancCancData2, columns=filtRawPancCancData2.columns)\n",
    "scaledRawPancCancData2[\"Diagnosis\"] = 1\n",
    "print(scaledRawPancCancData2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "0   0.414311 -0.426343 -0.236257   -0.017511          1\n",
      "1  -0.650777 -0.410380  2.585011   -0.327887          1\n",
      "2  -0.604525 -0.274486 -0.232637    0.429868          1\n",
      "3  -0.677115 -0.231455 -0.035300   -0.620078          1\n",
      "4  -0.711162  1.793484 -0.236383    0.825719          1\n",
      "..       ...       ...       ...         ...        ...\n",
      "74 -0.671334 -0.438558 -0.175120   -1.329337          1\n",
      "75  0.529300  0.740066 -0.236383    0.123129          1\n",
      "76 -0.502384 -0.402745  0.258267   -1.282659          1\n",
      "77 -0.117591 -0.433005 -0.236358   -0.274541          1\n",
      "78  2.821360 -0.438558 -0.236383   -0.073282          1\n",
      "\n",
      "[79 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "rowsToKeep = [\"GPX1\", \"LYVE1\", \"REG1B\", \"TFF1\"]\n",
    "#print(rawPancCancData3)\n",
    "\n",
    "filtRawPancCancData3 = rawPancCancData3[rawPancCancData3['index'].isin(rowsToKeep)]\n",
    "#print(filtRawPancCancData3.shape)\n",
    "#print(filtRawPancCancData3)\n",
    "\n",
    "filtRawPancCancData3 = filtRawPancCancData3.transpose()\n",
    "#print(filtRawPancCancData3)\n",
    "filtRawPancCancData3.reset_index(inplace=True, drop=True)\n",
    "#print(filtRawPancCancData3)\n",
    "#print(filtRawPancCancData3.shape)\n",
    "\n",
    "filtRawPancCancData3.columns = filtRawPancCancData3.iloc[0]\n",
    "filtRawPancCancData3 = filtRawPancCancData3[1:]\n",
    "\n",
    "filtRawPancCancData3.rename(columns={'Reg1': 'REG1B', \"GPX1\": \"Creatinine\", \"Tff1\": \"TFF1\", \"Lyve1\": \"LYVE1\"}, inplace=True)\n",
    "columnOrder = [\"LYVE1\", \"TFF1\", \"REG1B\", \"Creatinine\"]\n",
    "# Reorder the columns in the DataFrame\n",
    "filtRawPancCancData3 = filtRawPancCancData3[columnOrder]#print(filtRawPancCancData3)\n",
    "#print(filtRawPancCancData3.shape)\n",
    "\n",
    "# Impute missing values in each column if needed\n",
    "filtRawPancCancData3 = filtRawPancCancData3.fillna(filtRawPancCancData3.median())\n",
    "#print(filtRawPancCancData3)\n",
    "\n",
    "filtRawPancCancData1Scaler3 = StandardScaler()\n",
    "scaledRawPancCancData3 = filtRawPancCancData1Scaler3.fit_transform(filtRawPancCancData3)\n",
    "scaledRawPancCancData3 = pd.DataFrame(scaledRawPancCancData3, columns=filtRawPancCancData3.columns)\n",
    "scaledRawPancCancData3[\"Diagnosis\"] = 1\n",
    "print(scaledRawPancCancData3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "0  -0.315544  2.008313 -0.543365   -0.046518          1\n",
      "1  -0.581683  2.415103 -0.534482   -0.740781          1\n",
      "2  -0.585285  2.299507 -0.489057    0.271683          1\n",
      "3  -0.750723  0.599046 -0.452496   -0.729316          1\n",
      "4   0.046597 -0.554481 -0.160474    1.918426          1\n",
      "..       ...       ...       ...         ...        ...\n",
      "74 -0.671334 -0.438558 -0.175120   -1.329337          1\n",
      "75  0.529300  0.740066 -0.236383    0.123129          1\n",
      "76 -0.502384 -0.402745  0.258267   -1.282659          1\n",
      "77 -0.117591 -0.433005 -0.236358   -0.274541          1\n",
      "78  2.821360 -0.438558 -0.236383   -0.073282          1\n",
      "\n",
      "[111 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the pancreatic cancer data\n",
    "allPancCancData = pd.concat([scaledRawPancCancData1, scaledRawPancCancData2, scaledRawPancCancData3], sort=False)\n",
    "print(allPancCancData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "0   0.603023 -1.177057 -0.312348    0.761342          0\n",
      "1  -0.527645 -1.177057 -0.312348    1.162652          0\n",
      "2  -0.527645  2.075338 -0.312348    0.069336          0\n",
      "3  -0.527645  0.449140  2.030259    0.732340          0\n",
      "4  -0.527645 -0.247802 -0.312348   -0.348836          0\n",
      "..       ...       ...       ...         ...        ...\n",
      "74 -0.671334 -0.438558 -0.175120   -1.329337          1\n",
      "75  0.529300  0.740066 -0.236383    0.123129          1\n",
      "76 -0.502384 -0.402745  0.258267   -1.282659          1\n",
      "77 -0.117591 -0.433005 -0.236358   -0.274541          1\n",
      "78  2.821360 -0.438558 -0.236383   -0.073282          1\n",
      "\n",
      "[250 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Concatenate the additional dataset\n",
    "ncbiDataset = pd.concat([allPancNormData, allPancCancData], sort=False)\n",
    "print(ncbiDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length is 200... test length is 50\n",
      "train_urinary_data: \n",
      "        LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "27 -0.577293 -0.498533 -0.160845   -1.005056          0\n",
      "16 -0.601634 -0.602931 -0.222204    1.325185          0\n",
      "51 -0.575617 -0.315712 -0.233693   -0.976526          1\n",
      "18  0.266584 -0.365430  0.443695   -1.022374          1\n",
      "56 -0.577293 -0.856202 -0.160845   -0.164947          0\n",
      "..       ...       ...       ...         ...        ...\n",
      "57 -0.577293 -0.625448 -0.160845   -1.098712          0\n",
      "26 -0.649492  0.894282 -0.211068    0.181930          1\n",
      "12 -0.575617 -0.198974 -0.236383    0.794196          1\n",
      "3  -0.677115 -0.231455 -0.035300   -0.620078          1\n",
      "50 -0.032524  1.220588 -0.160845   -0.317312          0\n",
      "\n",
      "[200 rows x 5 columns]\n",
      "test_urinary_data: \n",
      "        LYVE1      TFF1     REG1B  Creatinine  Diagnosis\n",
      "3   1.992331  1.282733 -0.222204   -1.322138          0\n",
      "42  0.568486 -0.351525  0.377223    0.261343          1\n",
      "9  -0.601634 -0.602931 -0.222204   -0.294469          0\n",
      "6  -0.527645 -0.944743 -0.312348   -0.092537          0\n",
      "29  1.057015 -0.498533 -0.160845   -0.806561          0\n",
      "35  2.783459 -0.439113 -0.236383    0.235882          1\n",
      "69 -0.679685  0.232443 -0.124567   -1.062607          1\n",
      "41 -0.601634 -0.602931 -0.222204    0.065146          0\n",
      "34  1.057015  0.124504 -0.160845   -1.445379          0\n",
      "11  0.603023 -1.177057 -0.312348    0.634542          0\n",
      "43 -0.101531 -0.271987 -0.236383   -0.196341          1\n",
      "20 -0.838928 -0.754403  0.437871    2.490400          1\n",
      "25 -0.720798 -0.220351 -0.236056    2.513391          1\n",
      "1  -0.581683  2.415103 -0.534482   -0.740781          1\n",
      "20  0.512246  1.012909 -0.160845    1.966778          0\n",
      "15  2.292054 -0.001918  3.931583    2.360045          0\n",
      "36 -0.214592 -0.439113 -0.236383   -0.286059          1\n",
      "3  -0.750723  0.599046 -0.452496   -0.729316          1\n",
      "9   5.415171 -0.452382 -0.160845   -0.064301          0\n",
      "46 -0.577293  2.270520 -0.160845    0.225054          0\n",
      "12  0.512246 -0.660061 -0.160845    0.222259          0\n",
      "13 -0.601634 -0.602931 -0.222204    0.060106          0\n",
      "38  0.285833 -0.438974 -0.236383   -0.395176          1\n",
      "40  0.453497 -0.431201 -0.236358   -0.480651          1\n",
      "15 -0.479314 -0.754403 -0.502960    0.270555          1\n",
      "5  -0.032524  0.424485 -0.160845    1.434196          0\n",
      "33 -0.601634 -0.032020 -0.222204    0.589219          0\n",
      "34 -0.062987 -0.439113 -0.236383   -0.112685          1\n",
      "39 -0.032524 -0.533146 -0.160845   -0.912798          0\n",
      "18 -0.671334 -0.269211 -0.013279   -1.264473          1\n",
      "18 -0.601634 -0.108451 -0.222204   -1.355897          0\n",
      "19 -0.577293  1.082135 -0.160845    1.977961          0\n",
      "13 -0.527645  0.681454  4.372865   -0.212593          0\n",
      "14  1.733690 -0.247802 -0.312348   -0.626718          0\n",
      "33  0.213242  6.010071 -0.236383    3.174154          1\n",
      "64  1.079831 -0.439113 -0.236383    1.724114          1\n",
      "12 -0.601634 -0.602931 -0.222204    0.497534          0\n",
      "60 -0.617373  0.453426  0.003589   -1.284478          1\n",
      "17  1.601785 -0.683136 -0.160845   -0.100645          0\n",
      "1  -0.527645 -1.177057 -0.312348    1.162652          0\n",
      "18  0.603023  0.216826 -0.312348   -0.670558          0\n",
      "13 -0.626366  1.559175 -0.236056    0.561414          1\n",
      "51 -0.577293 -0.775438 -0.160845   -1.076346          0\n",
      "65 -0.504311  0.835705 -0.231254   -0.387295          1\n",
      "8   0.056674 -0.602712 -0.521555   -0.034005          1\n",
      "45 -0.586538 -0.438697 -0.236383    0.095243          1\n",
      "28 -0.577293  0.447560 -0.160845    0.873658          0\n",
      "17 -0.601634 -0.385824 -0.222204    1.636096          0\n",
      "37 -0.670049 -0.375400  8.150069    1.948409          1\n",
      "68 -0.653989 -0.424816 -0.236332   -0.887414          1\n"
     ]
    }
   ],
   "source": [
    "# Split data into training/validation and test (80/20)\n",
    "\n",
    "train_ncbi_data, test_ncbi_data = train_test_split(ncbiDataset, test_size=0.2, random_state=4, shuffle=True)\n",
    "\n",
    "print(\"train length is \" + str(len(train_ncbi_data)) + \"... test length is \" + str(len(test_ncbi_data)))\n",
    "print(\"train_urinary_data: \\n\", train_ncbi_data)\n",
    "print(\"test_urinary_data: \\n\", test_ncbi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: add/remove/adjust hyperparameters as you see fit\n",
    "rf_ncbi = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb_ncbi = XGBClassifier(n_estimators=100, random_state=42, learning_rate=0.01)\n",
    "svm_ncbi = SVC(C=1, kernel=\"rbf\", random_state=42)\n",
    "gnb_ncbi = GaussianNB()\n",
    "knn_ncbi = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF training accuracies:  [1.0, 0.95, 0.9, 0.95, 0.95, 1.0, 1.0, 0.85, 0.95, 0.95]\n",
      "RF mean:  0.9499999999999998\n",
      "RF standard dev:  0.0447213595499958 \n",
      "\n",
      "XGB training accuracies:  [0.95, 0.9, 0.95, 0.75, 0.95, 1.0, 1.0, 0.9, 1.0, 0.95]\n",
      "XGB mean:  0.9349999999999998\n",
      "XGB standard dev:  0.07088723439378912 \n",
      "\n",
      "SVM training accuracies:  [0.6, 0.75, 0.6, 0.45, 0.55, 0.5, 0.45, 0.35, 0.5, 0.55]\n",
      "SVM mean:  0.53\n",
      "SVM standard dev:  0.10295630140987 \n",
      "\n",
      "GNB training accuracies:  [0.45, 0.4, 0.3, 0.5, 0.5, 0.5, 0.4, 0.55, 0.45, 0.6]\n",
      "GNB mean:  0.465\n",
      "GNB standard dev:  0.08077747210701756 \n",
      "\n",
      "KNN training accuracies:  [0.9, 0.65, 0.6, 0.6, 0.65, 0.7, 0.65, 0.3, 0.7, 0.55]\n",
      "KNN mean:  0.63\n",
      "KNN standard dev:  0.14177446878757824 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "rf_ncbi_scores = []\n",
    "xgb_ncbi_scores = []\n",
    "svm_ncbi_scores = []\n",
    "gnb_ncbi_scores = []\n",
    "knn_ncbi_scores = []\n",
    "\n",
    "X = train_ncbi_data\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, val_index in kf.split(X): #10 folds\n",
    "    # set up training data\n",
    "    train_chunk = X.iloc[train_index]\n",
    "    y_train = train_chunk['Diagnosis']\n",
    "    X_train = train_chunk.drop(columns=['Diagnosis'])\n",
    "\n",
    "    # set up validation data\n",
    "    val_chunk = X.iloc[val_index]\n",
    "    y_val = val_chunk['Diagnosis']\n",
    "    X_val = val_chunk.drop(columns=['Diagnosis'])\n",
    "\n",
    "    # Random Forest\n",
    "    rf_ncbi.fit(X_train, y_train)\n",
    "    rf_pred = rf_ncbi.predict(X_val)\n",
    "    rf_score = accuracy_score(y_val, rf_pred)\n",
    "    rf_ncbi_scores.append(rf_score)\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_ncbi.fit(X_train, y_train)\n",
    "    xgb_pred = xgb_ncbi.predict(X_val)\n",
    "    xgb_score = accuracy_score(y_val, xgb_pred)\n",
    "    xgb_ncbi_scores.append(xgb_score)\n",
    "\n",
    "    # SVM\n",
    "    svm_ncbi.fit(X_train, y_train)\n",
    "    svm_pred = svm_ncbi.predict(X_val)\n",
    "    svm_score = accuracy_score(y_val, svm_pred)\n",
    "    svm_ncbi_scores.append(svm_score)\n",
    "\n",
    "    # Gaussian Naive Bayes\n",
    "    gnb_ncbi.fit(X_train, y_train)\n",
    "    gnb_pred = gnb_ncbi.predict(X_val)\n",
    "    gnb_score = accuracy_score(y_val, gnb_pred)\n",
    "    gnb_ncbi_scores.append(gnb_score)\n",
    "\n",
    "    # KNearestNeighbors\n",
    "    knn_ncbi.fit(X_train, y_train)\n",
    "    knn_pred = knn_ncbi.predict(X_val)\n",
    "    knn_score = accuracy_score(y_val, knn_pred)\n",
    "    knn_ncbi_scores.append(knn_score)\n",
    "\n",
    "print(\"RF training accuracies: \", rf_ncbi_scores)\n",
    "print(\"RF mean: \", np.mean(rf_ncbi_scores))\n",
    "print(\"RF standard dev: \", np.std(rf_ncbi_scores), \"\\n\")\n",
    "\n",
    "print(\"XGB training accuracies: \", xgb_ncbi_scores)\n",
    "print(\"XGB mean: \", np.mean(xgb_ncbi_scores))\n",
    "print(\"XGB standard dev: \", np.std(xgb_ncbi_scores), \"\\n\")\n",
    "\n",
    "print(\"SVM training accuracies: \", svm_ncbi_scores)\n",
    "print(\"SVM mean: \", np.mean(svm_ncbi_scores))\n",
    "print(\"SVM standard dev: \", np.std(svm_ncbi_scores), \"\\n\")\n",
    "\n",
    "print(\"GNB training accuracies: \", gnb_ncbi_scores)\n",
    "print(\"GNB mean: \", np.mean(gnb_ncbi_scores))\n",
    "print(\"GNB standard dev: \", np.std(gnb_ncbi_scores), \"\\n\")\n",
    "\n",
    "print(\"KNN training accuracies: \", knn_ncbi_scores)\n",
    "print(\"KNN mean: \", np.mean(knn_ncbi_scores))\n",
    "print(\"KNN standard dev: \", np.std(knn_ncbi_scores), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF test accuracy:  0.96\n",
      "XGB test accuracy:  0.94\n",
      "SVM test accuracy:  0.52\n",
      "GNB test accuracy:  0.5\n",
      "KNN test accuracy:  0.6\n"
     ]
    }
   ],
   "source": [
    "# set up test data\n",
    "X_test = test_ncbi_data.drop(columns=['Diagnosis'])\n",
    "y_test = test_ncbi_data['Diagnosis']\n",
    "\n",
    "# Random Forest\n",
    "rf_ncbi_pred = rf_ncbi.predict(X_test)\n",
    "rf_ncbi_acc = accuracy_score(y_test, rf_ncbi_pred)\n",
    "print(\"RF test accuracy: \", rf_ncbi_acc)\n",
    "\n",
    "# XGBoost\n",
    "xgb_ncbi_pred = xgb_ncbi.predict(X_test)\n",
    "xgb_ncbi_acc = accuracy_score(y_test, xgb_ncbi_pred)\n",
    "print(\"XGB test accuracy: \", xgb_ncbi_acc)\n",
    "\n",
    "# SVM\n",
    "svm_ncbi_pred = svm_ncbi.predict(X_test)\n",
    "svm_ncbi_acc = accuracy_score(y_test, svm_ncbi_pred)\n",
    "print(\"SVM test accuracy: \", svm_ncbi_acc)\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb_ncbi_pred = gnb_ncbi.predict(X_test)\n",
    "gnb_ncbi_acc = accuracy_score(y_test, gnb_ncbi_pred)\n",
    "print(\"GNB test accuracy: \", gnb_ncbi_acc)\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_ncbi_pred = knn_ncbi.predict(X_test)\n",
    "knn_ncbi_acc = accuracy_score(y_test, knn_ncbi_pred)\n",
    "print(\"KNN test accuracy: \", knn_ncbi_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- SIGNIFICANCE ANALYSIS -----\n",
    "# Significance Analysis of Results\n",
    "\n",
    "- Do the McNemar test here for each of the models (10?) to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTHOUGHTS: SHOULD WE DO IT BETWEEN THE BEST 2 MODELS IN EACH DATASET?\\nOR BEST AND WORST? I DON'T THINK WE SHOULD DO IT BETWEEN THE MODELS FOR \\nDIFFERENT DATASETS, THAT'S NOT A FAIR COMPARISON\\n\\n\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "'''\n",
    "THOUGHTS: SHOULD WE DO IT BETWEEN THE BEST 2 MODELS IN EACH DATASET?\n",
    "OR BEST AND WORST? I DON'T THINK WE SHOULD DO IT BETWEEN THE MODELS FOR \n",
    "DIFFERENT DATASETS, THAT'S NOT A FAIR COMPARISON\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#Idea is below:\n",
    "\n",
    "#        Classifier2 Correct, Classifier2 Incorrect\n",
    "#Classifier1 Correct:         ?? ??\n",
    "#Classifier1 Incorrect:       ?? ??\n",
    "\n",
    "#make a contingency table like below for 2 classifiers\n",
    "#table = [[4, 2],\n",
    "#\t\t [1, 3]]\n",
    "\n",
    "\n",
    "#result = mcnemar(table, exact=True, correction=True)\n",
    "#print(result.statistic)\n",
    "#print(result.pvalue)\n",
    "#reject null hypothesis if below 0.05?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Across Datasets\n",
    "- PROBABLY NEEDS TO BE MOVED TO VERY BOTTOM\n",
    "- take urinary dataset models and try to predict on other dataset's test samples and vice versa\n",
    "    - draw conclusions on the accuracy percentage and based on this, we can determine if the urinary biomarkers\n",
    "        - are generalizeable to use on other data for predicting pancreatic cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URINARY MODELS\n",
      "RF test accuracy:  0.48\n",
      "XGB test accuracy:  0.48\n",
      "SVM test accuracy:  0.5\n",
      "GNB test accuracy:  0.46\n",
      "KNN test accuracy:  0.54\n",
      "GOING TO NCBI MODELS\n",
      "RF test accuracy:  0.3559322033898305\n",
      "XGB test accuracy:  0.3813559322033898\n",
      "SVM test accuracy:  0.6949152542372882\n",
      "GNB test accuracy:  0.6949152542372882\n",
      "KNN test accuracy:  0.559322033898305\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"URINARY MODELS\")\n",
    "# URINARY MODELS ON NCBI DATASET\n",
    "X_ncbi_test = test_ncbi_data.drop(columns=['Diagnosis'])\n",
    "y_ncbi_test = test_ncbi_data['Diagnosis']\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "rf_pred = rf.predict(X_ncbi_test)\n",
    "rf_acc = accuracy_score(y_ncbi_test, rf_pred)\n",
    "print(\"RF test accuracy: \", rf_acc)\n",
    "\n",
    "# XGBoost\n",
    "xgb_pred = xgb.predict(X_ncbi_test)\n",
    "xgb_acc = accuracy_score(y_ncbi_test, xgb_pred)\n",
    "print(\"XGB test accuracy: \", xgb_acc)\n",
    "\n",
    "# SVM\n",
    "svm_pred = svm.predict(X_ncbi_test)\n",
    "svm_acc = accuracy_score(y_ncbi_test, svm_pred)\n",
    "print(\"SVM test accuracy: \", svm_acc)\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb_pred = gnb.predict(X_ncbi_test)\n",
    "gnb_acc = accuracy_score(y_ncbi_test, gnb_pred)\n",
    "print(\"GNB test accuracy: \", gnb_acc)\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_pred = knn.predict(X_ncbi_test)\n",
    "knn_acc = accuracy_score(y_ncbi_test, knn_pred)\n",
    "print(\"KNN test accuracy: \", knn_acc)\n",
    "\n",
    "\n",
    "\n",
    "#######################\n",
    "\n",
    "\n",
    "print(\"GOING TO NCBI MODELS\")\n",
    "# NCBI MODELS ON URINARY DATASET\n",
    "X_urinary_test = test_urinary_data.drop(columns=['Diagnosis'])\n",
    "y_urinary_test = test_urinary_data['Diagnosis']\n",
    "\n",
    "# Random Forest\n",
    "rf_ncbi_pred = rf_ncbi.predict(X_urinary_test)\n",
    "rf_ncbi_acc = accuracy_score(y_urinary_test, rf_ncbi_pred)\n",
    "print(\"RF test accuracy: \", rf_ncbi_acc)\n",
    "\n",
    "# XGBoost\n",
    "xgb_ncbi_pred = xgb_ncbi.predict(X_urinary_test)\n",
    "xgb_ncbi_acc = accuracy_score(y_urinary_test, xgb_ncbi_pred)\n",
    "print(\"XGB test accuracy: \", xgb_ncbi_acc)\n",
    "\n",
    "# SVM\n",
    "svm_ncbi_pred = svm_ncbi.predict(X_urinary_test)\n",
    "svm_ncbi_acc = accuracy_score(y_urinary_test, svm_ncbi_pred)\n",
    "print(\"SVM test accuracy: \", svm_ncbi_acc)\n",
    "\n",
    "# Gaussian Naive Bayes\n",
    "gnb_ncbi_pred = gnb_ncbi.predict(X_urinary_test)\n",
    "gnb_ncbi_acc = accuracy_score(y_urinary_test, gnb_ncbi_pred)\n",
    "print(\"GNB test accuracy: \", gnb_ncbi_acc)\n",
    "\n",
    "# KNearestNeighbors\n",
    "knn_ncbi_pred = knn_ncbi.predict(X_urinary_test)\n",
    "knn_ncbi_acc = accuracy_score(y_urinary_test, knn_ncbi_pred)\n",
    "print(\"KNN test accuracy: \", knn_ncbi_acc)\n",
    "\n",
    "\n",
    "\n",
    "#########################\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
