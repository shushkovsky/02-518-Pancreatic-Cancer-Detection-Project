{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pancreatic Cancer Detection Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing \n",
    "\n",
    "Ideas we should probably do for both datasets:\n",
    "    - load data. remove any Null/NaN data, see if there are negative values and remove those if applicable.\n",
    "    - if blank data cells, impute the data. scale the appropriate data columns\n",
    "\n",
    "\n",
    "    - split the dataset into X and y subsets for passing into models\n",
    "        - which really means also split into 80/20; 80% training(validation included) and 20% test\n",
    "\n",
    "    - Note: we should do some data visualizations --> heatmaps? histograms of label distributions for proof\n",
    "        - of good splits. mutual information??? (need to better understand if its useful)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation\n",
    "\n",
    "- we want to initialize all 4 models, probably default hyperparameters for most values.\n",
    "    - it's 4 models per dataset, so we'll have 8 in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation\n",
    "\n",
    "- Train the models using 10-fold cross validation \n",
    "    - we can probably do this in 2 separate cross-validation loops. \n",
    "        - first one is for urinary dataset and we train/validate all 4 models (get their scores and loss? too)\n",
    "        - repeat for second dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Models\n",
    "\n",
    "- Test each of the models on the appropriate dataset and store values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significance Analysis of Results\n",
    "\n",
    "- Do the McNemar test here for each of the models (8?) to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Across Datasets\n",
    "\n",
    "- take urinary dataset models and try to predict on other dataset's test samples and vice versa\n",
    "    - draw conclusions on the accuracy percentage and based on this, we can determine if the urinary biomarkers\n",
    "        - are generalizeable to use on other data for predicting pancreatic cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------- NON URINARY DATA WORK --------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawPancCancData1 = pd.read_csv(\"pancreaticCancerSeqData/GSE232860_allsamples.deseq.normalized.counts.csv\")\n",
    "#print(rawPancCancData1.shape)\n",
    "\n",
    "\n",
    "#Slow loading, 48,553 rows\n",
    "#rawPancCancData2 = pd.read_excel(\"pancreaticCancerSeqData/GSE245306_FKPM.xlsx\")\n",
    "#print(rawPancCancData2.shape)\n",
    "\n",
    "#59050 rows\n",
    "rawPancCancData3 = pd.read_csv(\"pancreaticCancerSeqData/tumor.counts.sub.tsv\", sep='\\t')\n",
    "#print(rawPancCancData3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17966, 23)\n",
      "0        Tff1          Reg1A       Lyve1          Gpx1          Reg1B\n",
      "1   86.519650    1152.208802  111.477242   7915.716067    1152.208802\n",
      "2   99.259037    2032.652444   81.133473   6992.151782    2032.652444\n",
      "3   95.638935    6535.034757   80.722771   8339.013202    6535.034757\n",
      "4   42.385798   10158.844770   61.860354   7007.403411   10158.844770\n",
      "5    6.260937   39103.310850  152.766873  10529.644580   39103.310850\n",
      "6   33.793363    6810.356633  189.839188   7140.338886    6810.356633\n",
      "7    4.244787    3628.231888  217.545346   8391.944362    3628.231888\n",
      "8    2.204342   60100.287620  598.478904   6179.873328   60100.287620\n",
      "9    4.750487    3313.939555  153.915771   7932.362771    3313.939555\n",
      "10  21.847610   16311.226750  294.942730   6057.746312   16311.226750\n",
      "11  42.165889    2393.872495  151.413873   8880.711134    2393.872495\n",
      "12  35.099226    1474.167487  128.697162   6995.958204    1474.167487\n",
      "13   0.000000   82462.293950   26.049017   8902.410494   82462.293950\n",
      "14   7.920592   73107.061400  117.488777   6914.676555   73107.061400\n",
      "15  25.489878   72214.523880  129.148716   8844.987689   72214.523880\n",
      "16   0.000000    5156.973066   92.805067   8337.512807    5156.973066\n",
      "17   0.000000  476139.735800  114.099453   6897.583625  476139.735800\n",
      "18   0.000000    1093.919310   92.606926   9185.449446    1093.919310\n",
      "19  12.181416   98986.799420  177.848681   6617.554505   98986.799420\n",
      "20   0.000000   40920.243230  100.045418   9186.670473   40920.243230\n",
      "21   0.000000   98409.599640   51.803614  11290.531360   98409.599640\n",
      "22   0.000000  108693.029400  119.300066   6966.929880  108693.029400\n",
      "[[ 2.00831313 -0.54336456 -0.3155444  -0.04651845 -0.54336456]\n",
      " [ 2.41510286 -0.53448171 -0.58168258 -0.74078094 -0.53448171]\n",
      " [ 2.29950702 -0.48905691 -0.58528476  0.27168282 -0.48905691]\n",
      " [ 0.59904605 -0.45249607 -0.75072266 -0.72931598 -0.45249607]\n",
      " [-0.55448065 -0.1604736   0.04659742  1.91842603 -0.1604736 ]\n",
      " [ 0.32467536 -0.48627917  0.37175012 -0.62938561 -0.48627917]\n",
      " [-0.61885967 -0.51838382  0.61475443  0.31147228 -0.51838382]\n",
      " [-0.68401446  0.05136616  3.95583465 -1.35138756  0.05136616]\n",
      " [-0.60271185 -0.52155473  0.05667413 -0.03400477 -0.52155473]\n",
      " [-0.05677236 -0.39042431  1.29358901 -1.44319298 -0.39042431]\n",
      " [ 0.59202398 -0.53083734  0.03473056  0.67888843 -0.53083734]\n",
      " [ 0.36637372 -0.5401163  -0.16451246 -0.73791958 -0.5401163 ]\n",
      " [-0.75440277  0.2769778  -1.06481562  0.69520029  0.2769778 ]\n",
      " [-0.50148514  0.18259229 -0.26281861 -0.79902068  0.18259229]\n",
      " [ 0.05953131  0.17358743 -0.16055199  0.65203438  0.17358743]\n",
      " [-0.75440277 -0.50296025 -0.47931373  0.27055494 -0.50296025]\n",
      " [-0.75440277  4.24881328 -0.29254559 -0.81186979  4.24881328]\n",
      " [-0.75440277 -0.54395265 -0.48105158  0.90796657 -0.54395265]\n",
      " [-0.36542994  0.44369453  0.26658415 -1.02237351  0.44369453]\n",
      " [-0.75440277 -0.14214246 -0.41581029  0.90888444 -0.14214246]\n",
      " [-0.75440277  0.43787113 -0.838928    2.49040046  0.43787113]\n",
      " [-0.75440277  0.54162127 -0.24693221 -0.75974077  0.54162127]]\n"
     ]
    }
   ],
   "source": [
    "#Only has Reg1, not Reg1B or Reg1A, so we take Reg1 and apply it to both rows\n",
    "rowsToKeep = [\"Gpx1\", \"Lyve1\", \"Reg1\", \"Tff1\", \"Reg1\"]\n",
    "rawPancCancData1.rename(columns={'Unnamed: 0': 'GeneNames'}, inplace=True)\n",
    "print(rawPancCancData1.shape)\n",
    "\n",
    "filtRawPancCancData1 = rawPancCancData1[rawPancCancData1['GeneNames'].isin(rowsToKeep)]\n",
    "filtRawPancCancData1 = filtRawPancCancData1.transpose()\n",
    "filtRawPancCancData1.reset_index(inplace=True, drop=True)\n",
    "filtRawPancCancData1.columns = filtRawPancCancData1.iloc[0]\n",
    "filtRawPancCancData1 = filtRawPancCancData1[1:]\n",
    "\n",
    "filtRawPancCancData1[\"Reg1B\"] = filtRawPancCancData1[\"Reg1\"].copy()\n",
    "filtRawPancCancData1.rename(columns={'Reg1': 'Reg1A'}, inplace=True)\n",
    "\n",
    "# Impute missing values in each column if needed\n",
    "filtRawPancCancData1 = filtRawPancCancData1.fillna(filtRawPancCancData1.median())\n",
    "print(filtRawPancCancData1)\n",
    "\n",
    "\n",
    "#NOTE: Scale the X_train and X_test separately, once I have split the whole X data.\n",
    "#filtRawPancCancData1Scaler = StandardScaler()\n",
    "# transform data\n",
    "#scaledRawPancCancData1 = filtRawPancCancData1Scaler.fit_transform(filtRawPancCancData1)\n",
    "#print(scaledRawPancCancData1)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
